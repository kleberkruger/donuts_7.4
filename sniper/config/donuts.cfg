# Configuration file for DONUTS implementation
#
# Based on Xeon X5550 Gainestown
# See http://en.wikipedia.org/wiki/Gainestown_(microprocessor)#Gainestown
# and http://ark.intel.com/products/37106

#include donuts-base

[perf_model/core]
logical_cpus = 1 # number of SMT threads per core
frequency = 2.66

[caching_protocol]
type = parametric_dram_directory_msi

[perf_model/itlb]
size = 128              # Number of I-TLB entries
associativity = 4       # I-TLB associativity

[perf_model/dtlb]
size = 64               # Number of D-TLB entries
associativity = 4       # D-TLB associativity

[perf_model/stlb]
size = 512              # Number of second-level TLB entries
associativity = 4       # S-TLB associativity

[perf_model/cache]
levels = 3

[perf_model/l1_icache]
cache_size = 32
associativity = 4
replacement_policy = lru
data_access_time = 4
tags_access_time = 1
writethrough = 0
shared_cores = 1

[perf_model/l1_dcache]
cache_size = 32
associativity = 8
replacement_policy = lru
data_access_time = 4
tags_access_time = 1
writethrough = 0
shared_cores = 1

[perf_model/l2_cache]
cache_size = 256
associativity = 8
replacement_policy = lru
data_access_time = 8 # 8.something according to membench, -1 cycle L1 tag access time
# http://www.realworldtech.com/page.cfm?ArticleID=RWT040208182719&p=7
tags_access_time = 3
# Total neighbor L1/L2 access time is around 40/70 cycles (60-70 when it's coming out of L1)
writeback_time = 50 # L3 hit time will be added
writethrough = 0
shared_cores = 1

[perf_model/l3_cache]
cache_block_size = 64
dvfs_domain = global # L1 and L2 run at core frequency (default), L3 is system frequency
writeback_time = 0
cache_size = 8192
associativity = 16
replacement_policy = lrur
cache_set_threshold = 0.75
cache_threshold = 0.6
data_access_time = 30 # 35 cycles total according to membench, +L1+L2 tag times
tags_access_time = 10
writethrough = 0
shared_cores = 4

[perf_model/dram_directory]
# total_entries = number of entries per directory controller.
total_entries = 1048576
associativity = 16
directory_type = full_map

[perf_model/dram]
# -1 means that we have a number of distributed DRAM controllers (4 in this case)
num_controllers = -1
controllers_interleaving = 4
# DRAM access latency in nanoseconds. Should not include L1-LLC tag access time, directory access time (14 cycles = 5.2 ns),
# or network time [(cache line size + 2*{overhead=40}) / network bandwidth = 18 ns]
# Membench says 175 cycles @ 2.66 GHz = 66 ns total
latency = 45
per_controller_bandwidth = 7.6              # In GB/s, as measured by core_validation-dram
